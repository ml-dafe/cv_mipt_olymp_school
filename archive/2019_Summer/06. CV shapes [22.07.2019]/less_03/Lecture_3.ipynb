{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Thresholding\n",
    "Здесь все просто. Если значение пикселя больше порогового значения, ему присваивается одно значение (может быть белым), в противном случае ему присваивается другое значение (может быть черным). Используемая функция **cv2.threshold(src, thresh, maxval, type)**\n",
    "\n",
    "* **src** $-$ исходное изображение, которое должно быть изображением в градациях серого\n",
    "* **thresh** $-$ пороговое значение, которое используется для классификации значений пикселей\n",
    "* **maxval** $-$ представляет значение, которое будет дано, если значение пикселя больше (иногда меньше) порогового значения\n",
    "* **type** $-$ предоставляет различные стили порогового значения.\n",
    "\n",
    "Различные типы:\n",
    "1. cv2.THRESH_BINARY\n",
    "2. cv2.THRESH_BINARY_INV\n",
    "3. cv2.THRESH_TRUNC\n",
    "4. cv2.THRESH_TOZERO\n",
    "5. cv2.THRESH_TOZERO_INV\n",
    "\n",
    "На выходе функция возвращает два значения. Первый $-$ **retval**, которое будет объяснено позже. Второй $-$ **thresholded image**.\n",
    "\n",
    "Подробнее в [документации](https://docs.opencv.org/3.4.2/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57).\n",
    "\n",
    "Рассмотрим разные типы threshold на примере градиента серого цвета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img/grad_grayscale.png',0)\n",
    "\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "plt.figure(figsize=(10,8))\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Thresholding\n",
    "В предыдущем разделе мы использовали глобальное значение в качестве порогового значения. Но это может быть не хорошо во всех условиях, когда изображение имеет разные условия освещения в разных областях. В этом случае мы идем на адаптивный порог. При этом алгоритм вычисляет порог для небольших областей изображения. Таким образом, мы получаем разные пороговые значения для разных областей одного и того же изображения, и это дает нам лучшие результаты для изображений с разной освещенностью.\n",
    "\n",
    "Он имеет три «специальных» входных параметра и только один выходной аргумент.\n",
    "\n",
    "Адаптивный метод $-$ **cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C)** - решает, как рассчитывается пороговое значение.\n",
    "\n",
    "* **thresholdType**:\n",
    "    * *cv2.ADAPTIVE_THRESH_MEAN_C*: пороговое значение является средним значением области соседства.\n",
    "\n",
    "    * *cv2.ADAPTIVE_THRESH_GAUSSIAN_C*: пороговое значение представляет собой взвешенную сумму значений окрестностей, где веса представляют собой гауссово окно.\n",
    "\n",
    "* **blockSize** $-$ определяет размер окна.\n",
    "\n",
    "* **C** $-$ это константа, которая вычитается из вычисленного среднего или взвешенного среднего.\n",
    "\n",
    "Ниже приведен фрагмент кода, сравнивающий глобальные пороги и адаптивные пороги для изображения с различным освещением:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гауссово окно? Что?\n",
    "\n",
    "Гауссова функция (гауссиан, гауссиана, функция Гаусса) — вещественная функция, описываемая следующей формулой:\n",
    "\n",
    "${\\displaystyle g\\left(x\\right)=a*exp{-{\\frac {(x-b)^{2}}{2c^{2}}}}}$\n",
    "\n",
    "Эта функция имеет широкое приминение в математической статистике. В таком случае параметры выражаются через среднеквадратичное отклонение ${\\displaystyle \\sigma }$ и математическое ожидание ${\\displaystyle \\mu }$ :\n",
    "\n",
    "${\\displaystyle a={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}}, {\\displaystyle b=\\mu }, {\\displaystyle c=\\sigma }$\n",
    "\n",
    "В двумерном виде она имеет такое представление:\n",
    "\n",
    "${\\displaystyle g(x,y)=A\\cdot exp{\\left(-\\left({\\frac {(x-x_{0})^{2}}{2\\sigma _{x}^{2}}}+{\\frac {(y-y_{0})^{2}}{2\\sigma _{y}^{2}}}\\right)\\right)}}$\n",
    "\n",
    "Стандартным статистическим способом мы определили ширину гауссовой формы в терминах $\\sigma$. Тем не менее, когда для сглаживания используется гауссиан, для сканеров характерно описывать ширину гауссиана с помощью другой связанной меры - полной ширины на половине максимума (FWHM).\n",
    "\n",
    "FWHM - ширина ядра, равная половине максимума высоты гауссианы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def fwhm2sigma(fwhm):\n",
    "    return fwhm / np.sqrt(8 * np.log(2))\n",
    "FWHM = 1\n",
    "sigma = fwhm2sigma(FWHM)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "dx = 0.1\n",
    "dy = 0.1\n",
    "x = np.arange(-6, 6, dx)\n",
    "y = np.arange(-6, 6, dy)\n",
    "x2d, y2d = np.meshgrid(x, y)\n",
    "kernel_2d = np.exp(-(x2d ** 2 + y2d ** 2) / (2 * sigma ** 2))\n",
    "kernel_2d = kernel_2d / (2 * np.pi * sigma ** 2) # unit integral\n",
    "ax.plot_surface(x2d, y2d, kernel_2d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, можно представить, что окно гаусса представляет из себя проекцию функции на плоскость. Проиллюстрировано на картинке:\n",
    "<img src=\"../img/gaus_win.png\" alt=\"Drawing\" style=\"width: 300px;\"/> \n",
    "\n",
    "Собственно, теперь перейдем к __threshold__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/sudoku.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "img = cv2.medianBlur(img,5)\n",
    "ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "plt.figure(figsize=(10,8))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бинаризация Оцу\n",
    "В первом разделе я говорил вам, что есть второй параметр retVal. Его использование происходит, когда мы идем на бинаризацию Оцу. Так что же это?\n",
    "\n",
    "В глобальном пороговом значении мы использовали произвольное значение для порогового значения, верно? Итак, как мы можем знать, что выбранное нами значение является хорошим или нет? Ответ, метод проб и ошибок. Но рассмотрим бимодальное изображение (проще говоря, бимодальное изображение - это изображение, гистограмма которого имеет два пика). Для этого изображения мы можем приблизительно принять значение в середине этих пиков в качестве порогового значения, верно? Это то, что делает бинаризация Оцу. Таким образом, простыми словами, он автоматически вычисляет пороговое значение из гистограммы изображения для бимодального изображения. (Для изображений, которые не являются бимодальными, бинаризация не будет точной.)\n",
    "\n",
    "Для этого используется наша функция **cv2.threshold()**, но передается дополнительный флаг *cv2.THRESH_OTSU*. Для порогового значения просто введите ноль. Затем алгоритм находит оптимальное пороговое значение и возвращает вас в качестве второго выхода retVal. Если пороговое значение Otsu не используется, **retVal** соответствует пороговому значению, которое вы использовали.\n",
    "\n",
    "Проверьте ниже пример. Входное изображение является шумным изображением. В первом случае я применил глобальный порог для значения $127$. Во втором случае я применил порог Оцу напрямую. В третьем случае я отфильтровал изображение с гауссовым ядром $5\\times5$, чтобы удалить шум, затем применил пороговое значение Оцу. Посмотрите, как фильтрация шума улучшает результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img/otsu_ex.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.random.rand(*noise_img.shape)*np.max(noise_img)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "img = noise_img\n",
    "\n",
    "# global thresholding\n",
    "ret1,th1 = cv2.threshold(img,170,255,cv2.THRESH_BINARY)\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "ret = [ret1, ret2, ret3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    "plt.figure(figsize=(14,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1] + ', threshold =' + str(ret[i])), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фичи. Больше глобальных фичей!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомним гистограммы\n",
    "\n",
    "### Сравнение гистограмм\n",
    "\n",
    "Вспомним функцию **cv2.CompareHist()**. Помимо меры корреляции между двумя гистограммами существуют и другие метрики:\n",
    "\n",
    "1. Correlation (method=CV_COMP_CORREL)\n",
    "\n",
    "$d(H_1,H_2) =  \\frac{\\sum_I (H_1(I) - \\bar{H_1}) (H_2(I) - \\bar{H_2})}{\\sqrt{\\sum_I(H_1(I) - \\bar{H_1})^2 \\sum_I(H_2(I) - \\bar{H_2})^2}}$, где $\\bar{H_k} =  \\frac{1}{N} \\sum _J H_k(J)$\n",
    "\n",
    "2. Chi-Square (method=CV_COMP_CHISQR)\n",
    "\n",
    "$d(H_1,H_2) =  \\sum _I  \\frac{\\left(H_1(I)-H_2(I)\\right)^2}{H_1(I)}$\n",
    "\n",
    "3. Intersection (method=CV_COMP_INTERSECT)\n",
    "\n",
    "$d(H_1,H_2) =  1 - \\sum _I  \\min (H_1(I), H_2(I))$\n",
    "\n",
    "4. Bhattacharyya distance (method=CV_COMP_BHATTACHARYYA).\n",
    "\n",
    "$d(H_1,H_2) =  \\sqrt{1 - \\frac{1}{\\sqrt{\\bar{H_1} \\bar{H_2} N^2}} \\sum_I \\sqrt{H_1(I) \\cdot H_2(I)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрицы смежности. Gray-Level Co-Occurrence Matrix (GLCM)\n",
    " \n",
    "Давайте искать неоднородности и разделять текстуры!\n",
    "\n",
    "<img src=\"https://i.ibb.co/y6FMPLX/image--022.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> \n",
    "\n",
    "Матрица частот пар пикселей определенной яркости, расположенных на\n",
    "изображении определенным образом относительно друг друга.\n",
    "\n",
    "<img src=\"https://i.ibb.co/hCSpx9Z/image--023.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> \n",
    "\n",
    "$(\\delta x, \\delta y)$ – параметр сдвига, задающий взаимное расположение пикселей;\n",
    "\n",
    "$I(p,q)$ – уровень яркости пикселя изображения, расположенного в точке $(p, q)$.\n",
    "\n",
    "\n",
    "__Пример матрицы смежности:__\n",
    "\n",
    "Тут $(\\delta x, \\delta y) = (1, 0)$\n",
    "<img src=\"https://i.ibb.co/7rGxztp/image--024.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> \n",
    "\n",
    "### Матрицы смежности: характиристики\n",
    "\n",
    "<img src=\"https://i.ibb.co/TLcs2Bz/image--025.jpg\" alt=\"Drawing\" style=\"width: 700px;\"/> \n",
    "\n",
    "Реализации в OpenCV такой функции нет. Только в __skimage__\n",
    "\n",
    "__from skimage.feature import greycomatrix, greycoprops__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свертки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы сверток\n",
    "**Свертки** $-$ это метод общей обработки сигналов. Люди, изучающие электронику, скажут вам о почти бесконечных бессонных ночах, которые были потрачены на их постижение. На эту тему написано множество книг. Но для компьютерного зрения мы просто разберемся с некоторыми простыми вещами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение\n",
    "Во-первых, давайте посмотрим на математическое определение свертки в дискретной области времени. Позже мы пройдемся по тому, что говорит нам это уравнение.\n",
    "${\\begin{align}y[n]&=x[n]*h[n]=\\sum_{k=-\\infty}^\\infty x[k]\\cdot h[n-k]\\end{align},}$\n",
    "\n",
    "где:\n",
    "* **x[n]** $-$ входой сигнал;\n",
    "* **h[n]** $-$ импульсный отклик; \n",
    "* **y[n]** $-$ выходной сигнал;\n",
    "* **$*$** $-$ обозначает свертку. \n",
    "\n",
    "Обратите внимание, что мы умножаем слагаемые $x[k]$ на смещенные по времени $h[n]$ и складываем их.\n",
    "Краеугольный камень понимания свертки лежит в основе импульсного отклика и импульсного разложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разложение импульсной функции\n",
    "\n",
    "Чтобы понять смысл свертки, мы собираемся начать с концепции разложения сигналов. Входной сигнал разлагается на простые аддитивные компоненты, и системный отклик входного сигнала приводит к сложению выходных данных этих компонентов, прошедших через систему.\n",
    "\n",
    "В общем, сигнал может быть разложен как взвешенная сумма базовых сигналов. Например, в рядах Фурье любой периодический сигнал (даже прямоугольный импульсный сигнал) может быть представлен суммой функций синуса и косинуса. Но здесь мы используем импульсные (дельта) функции для базовых сигналов, а не синус и косинус.\n",
    "\n",
    "Изучим следующий пример того, как сигнал разлагается на набор импульсных (дельта) функций:\n",
    "<img src=\"https://i.ibb.co/CKQ5sKh/conv_img01.png\" alt=\"Drawing\" style=\"width: 200px;\"/> \n",
    "\n",
    "Импульсная функция выглядит так: ${\\delta(n)={\\begin{cases}1, n=0\\\\ 0, n\\ne0 \\end{cases}}}$.  Тогда для данного примера $x[0]$ можно записать в виде ${x[0] = x[0] \\cdot \\delta[n-0] = 2 \\cdot \\delta[n-0]}$. Тогда $x[1]$ будет равен ${x[1] = x[1] \\cdot \\delta[n-1] = 3 \\cdot \\delta[n-1]}$, потому что ${\\delta[n-1]}$ равна $1$ при $n = 1$ и ноль в других случаях. Таким же образом мы можем записать ${x[2] = x[2] \\cdot \\delta[n-2] = 1 \\cdot \\delta[n-2]}$, сдвинув ${\\delta[n]}$ на 2. Следовательно, сигнал $x[n]$ может быть представлен добавлением $3$ сдвинутых и масштабированных импульсных функций.\n",
    "\n",
    "В общем, сигнал может быть записан как сумма масштабированных и сдвинутых дельта-функций:\n",
    "${\\begin{align}x[n]=\\sum_{k=0}^2 x[k]\\cdot\\delta[n-k]=x[0]\\cdot\\delta[n-0]+x[1]\\cdot\\delta[n-1]+x[2]\\cdot\\delta[n-2]\\end{align}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импульсивный отклик\n",
    "**Импульсный отклик** $-$ это выход системы, являющийся результатом импульсной функции в качестве входа.\n",
    "Именно это обозначается за $h[n]$. Все волшебство именно тут. Для вас это перестанет быть магией на 2-3 курсе инстиута. \n",
    "\n",
    "Существует огромное множество преобразования для импульсного отклика. Мы рассмотрим только конечные формулы без понимания того, как работает математика.\n",
    "\n",
    "<td> <img src=\"https://i.ibb.co/LNJ9h4L/conv_img02.png\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Свертка в 2D\n",
    "2D свертка является просто продолжением предыдущей 1D свертки путем свертки как горизонтального, так и вертикального направлений в двухмерной пространственной области. Свертка часто используется для обработки изображений, таких как сглаживание, повышение резкости и обнаружение краев изображений.\n",
    "\n",
    "Импульсная (дельта) функция также находится в двумерном пространстве, поэтому ${\\delta[m,n]={\\begin{cases}1,\\ m=n=0\\\\0,\\ m\\ne0,n\\ne0\\end{cases}}}$. Импульсный отклик в 2D обычно называют **«ядром»** или **«фильтром»** в обработке изображений.\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"https://i.ibb.co/RQZ0p5S/conv2d_delta.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "    <td> <img src=\"https://i.ibb.co/nCJMYR7/conv_img10.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Кроме того, выходные данные линейной и инвариантной по времени системы могут быть записаны путем свертки входного сигнала $x[m,n]$ и импульсной характеристики $h[m,n]$:\n",
    "${\\begin{align}y[m,n]=x[m,n]*h[m,n]=\\sum_{j=-\\infty}^\\infty \\sum_{i=-\\infty}^\\infty x[i,j]\\cdot h[m-i,n-j]\\end{align}}$\n",
    "\n",
    "Изучим пример, чтобы уточнить, как работает свертка в **2D**-пространстве.\n",
    "Допустим, что размер импульсного отклика (ядра) составляет $3\\times3$, а его значения **a, b, c, d, ...**\n",
    "\n",
    "Обратите внимание, что начало координат $(0,0)$ находится в центре ядра.\n",
    "\n",
    "Давайте выберем простейший пример и вычислим свертку, например, результат в $(1,1)$:\n",
    "<img src=\"https://i.ibb.co/K9mCCgy/conv_img11.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "${\\begin{align}\n",
    "y[1,1] & = \\sum_{j=0}^2 \\sum_{i=0}^2 x[i,j] \\cdot h[1-i,1-j]  \\\\ &\n",
    "= x[0,0] \\cdot h[1,1] + x[1,0] \\cdot h[0,1] + x[2,0] \\cdot h[-1,1] \\\\ &\n",
    "+ x[0,1] \\cdot h[1,0] + x[1,1] \\cdot h[0,0] + x[2,1] \\cdot h[-1,0] \\\\ &\n",
    "+ x[0,2] \\cdot h[1,-1] + x[1,2] \\cdot h[0,-1] + x[2,2] \\cdot h[-1,-1]\n",
    "\\end{align}}$\n",
    "\n",
    "Рассмотрим более конкртеный пример с двумерной сверткой. Предположим, у нас есть входные матрицы $3\\times3$ и ядра $3\\times3$ следующим образом:\n",
    "\n",
    "Input | Kernel | Output\n",
    "-|-|-\n",
    "<img src=\"https://i.ibb.co/1ZqbtRp/conv_img15.png\" alt=\"Drawing\" style=\"width: 200px;\"/> | <img src=\"https://i.ibb.co/mybNNbh/conv_img16.png\" alt=\"Drawing\" style=\"width: 200px;\"/> | <img src=\"https://i.ibb.co/hZKST86/conv_img17.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "Выходной сигнал в точке $(1,1)$ для этого примера будет:\n",
    "${\\begin{align}\n",
    "\\ y[1,1] & = \\sum_{j=0}^2 \\sum_{i=0}^2 x[i,j] \\cdot h[1-i,1-j]  \\\\ &\n",
    "\\ = x[0,0] \\cdot h[1,1] + x[1,0] \\cdot h[0,1] + x[2,0] \\cdot h[-1,1] \\\\ &\n",
    "\\ + x[0,1] \\cdot h[1,0] + x[1,1] \\cdot h[0,0] + x[2,1] \\cdot h[-1,0] \\\\ &\n",
    "\\ + x[0,2] \\cdot h[1,-1] + x[1,2] \\cdot h[0,-1] + x[2,2] \\cdot h[-1,-1] \\\\&\n",
    "\\ = 1 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 1 \\\\ &\n",
    "\\ + 4 \\cdot 0 + 5 \\cdot 0 + 6 \\cdot 0 \\\\ &\n",
    "\\ + 7 \\cdot (-1) + 8 \\cdot (-2) + 9 \\cdot (-1) \\\\ &\n",
    "\\ = -24 \\\\\n",
    "\\end{align}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Свертки в OpenCV (Фильтрация изображений)\n",
    "\n",
    "Как и в одномерных сигналах, изображения также могут быть отфильтрованы с помощью различных низкочастотных фильтров (LPF), высокочастотных фильтров (HPF) и т.д. \n",
    "**LPF** помогает удалять шумы, размывать изображения. Фильтры **HPF** помогают находить края в изображений.\n",
    "\n",
    "**OpenCV** предоставляет функцию **cv2.filter2D()** для объединения ядра с изображением. В качестве примера мы попробуем усредняющий фильтр на изображении. Ядро усредняющего фильтра $5\\times5$ будет выглядеть так:\n",
    "\n",
    "${\\begin{equation*}\n",
    "\\ K = \\frac{1}{25} \\begin{pmatrix}\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \n",
    "\\end{pmatrix}\n",
    "\\end{equation*}}$\n",
    "\n",
    "Свертка выполняется согласно теоретическим примерам выше. Как результат мы получаем осредненные пиксели своими 25 соседями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img/8_ka.jpg')\n",
    "## для отрисовки в pyplot\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), dtype=np.float32) / 25\n",
    "dst = cv2.filter2D(img.copy(), -1, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(dst);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Размытие изображения (Сглаживание изображения)\n",
    "Размытие изображения достигается путем свертывания изображения с помощью фильтра нижних частот. Это полезно для удаления шумов. Это фактически удаляет высокочастотный контент (например: шум, края) с изображения. Таким образом, края в этой операции немного размыты. (Ну, есть методы размытия, которые тоже не размывают края). **OpenCV** предоставляет в основном четыре типа техники размытия.\n",
    "\n",
    "Более подробное описание реализации фильтров OpenCV есть в [документации](https://docs.opencv.org/3.4.2/d4/d86/group__imgproc__filter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Усреднение\n",
    "Это делается путем свертки изображения с помощью нормализованного прямоугольного фильтра. Он просто берет среднее значение всех пикселей в области ядра и заменяет центральный элемент. Это выполняется функцией **cv2.blur()** или **cv2.boxFilter()**. Для более подробной информации о ядре посмотрите в документации. Мы должны указать ширину и высоту ядра. Нормализованный блочный фильтр $3\\times3$ будет выглядеть следующим образом:\n",
    "\n",
    "${\\begin{equation*}K = \\frac{1}{9} \n",
    "{\\begin{pmatrix}\n",
    "1 & \\ 1 & \\ 1 \\\\ \n",
    "1 & \\ 1 & \\ 1 \\\\ \n",
    "1 & \\ 1 & \\ 1 \\end{pmatrix}}\n",
    "\\end{equation*}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.blur(img,(3, 3))\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(blur);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Размытие по Гауссу\n",
    "При этом вместо box filter используется ядро Гаусса. Это делается с помощью функции **cv2.GaussianBlur()**. Мы должны указать ширину и высоту ядра, которые должны быть положительными и нечетными. Мы также должны указать стандартное отклонение в направлениях **X** и **Y**, **sigmaX** и **sigmaY** соответственно. Если указан только **sigmaX**, то **sigmaY** принимается так же, как **sigmaX**. Если оба даны в виде нулей, они рассчитываются по размеру ядра. Размытие по Гауссу очень эффективно для удаления гауссовского шума с изображения.\n",
    "\n",
    "Если вы хотите, вы можете создать ядро Гаусса с помощью функции **cv2.getGaussianKernel()**, а затем применить его с помощью **cv2.filter2D()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Код для размытия по Гауссу: \n",
    "\n",
    "blur = cv2.GaussianBlur(img,(9,9),0)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(blur);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Среднее размытие\n",
    "Здесь функция **cv2.medianBlur()** принимает медиану всех пикселей в области ядра, и центральный элемент заменяется этим медианным значением. Это очень эффективно против шума соли и перца на изображениях. Интересно, что в вышеупомянутых фильтрах центральным элементом является вновь вычисленное значение, которое может быть значением пикселя в изображении или новым значением. Но при медианном размытии центральный элемент всегда заменяется некоторым пиксельным значением на изображении. \n",
    "\n",
    "Эффективно снижает шум. Размер его ядра должен быть положительным нечетным целым числом.\n",
    "\n",
    "В этой демонстрации я добавил шум к нашему исходному изображению и применил медианное размытие. Проверьте результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.random.rand(*noise_img.shape)*np.max(noise_img)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "median = cv2.medianBlur(noise_img, 7)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(noise_img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(median);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Двусторонняя фильтрация\n",
    "\n",
    "**cv2.bilateralFilter()** очень эффективно удаляет шум, сохраняя края острыми. Но операция медленнее по сравнению с другими фильтрами. Мы уже видели, что фильтр Гаусса берет окрестность вокруг пикселя и находит его средневзвешенное значение по Гауссу. Этот гауссов фильтр является функцией только одного пространства, то есть при фильтрации учитываются соседние пиксели. Он не учитывает, имеют ли пиксели почти одинаковую интенсивность. Он не учитывает, является ли пиксель краевым или нет. Таким образом, это стирает края, что мы не хотим делать.\n",
    "\n",
    "Двусторонний фильтр также принимает гауссов фильтр в пространстве, но еще один гауссов фильтр, который является функцией разности пикселей. Гауссова функция пространства обеспечивает размытие только соседних пикселей, а гауссова функция разности интенсивности - размытие только тех пикселей, интенсивность которых равна центральной. Таким образом, он сохраняет края, поскольку пиксели на краях будут сильно изменяться.\n",
    "\n",
    "**Рекомендации к фильтру:**\n",
    "\n",
    "* **Sigma values:** для простоты вы можете установить два значения сигмы одинаковыми. Если они маленькие ($<10$), фильтр не будет иметь большого эффекта, тогда как если они большие ($>150$), они будут иметь очень сильный эффект, делая изображение мультяшным.\n",
    "\n",
    "* **Размер фильтра:** Большие фильтры (d$>5$) очень медленные, поэтому рекомендуется использовать d $=5$ для приложений реального времени и, возможно, d $=9$ для автономных приложений, которые нуждаются в сильной фильтрации шума.\n",
    "\n",
    "Ниже приведены примеры использования двустороннего фильтра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.random.rand(*noise_img.shape)*np.max(noise_img)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "bilateral = cv2.bilateralFilter(noise_img, d=15, sigmaColor=250, sigmaSpace=250)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(noise_img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(bilateral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Морфологические трансформации\n",
    "Морфологические преобразования $-$ это простые операции, основанные на форме изображения. Обычно это выполняется на двоичных изображениях. Он требует двух входных данных, один из которых является нашим исходным изображением, второй называется структурирующим элементом или ядром, которое определяет характер операции. Два основных морфологических оператора - это **эрозия** и **растягивание**. Затем его разновидности, такие как открытие, закрытие, градиент и т. д.\n",
    "\n",
    "**Эрозия** (размывание/сужение) изображения обычно используется для избавления от случайных вкраплений на изображении. Идея состоит в том, что вкрапления при размывании устранятся, тогда как крупные и соответсвенно более визуально-значимые регионы остаются.\n",
    "\n",
    "**Растягивание** (расширение) же, по идее, так же должно устранять шум и способствовать объединению областей изображения, которые были разделены шумом, тенями.\n",
    "Применение же небольшого растягивания должно сплавить эти области в одну.\n",
    "\n",
    "Морфологические операции, чаще всего, применяются над двоичными изображениями, которые получаются после порогового преобразования (thresholding).\n",
    "***\n",
    "**Подробнее с математической морфологией можно ознакомиться по этим ссылка: [1](https://ru.wikipedia.org/wiki/%CC%E0%F2%E5%EC%E0%F2%E8%F7%E5%F1%EA%E0%FF_%EC%EE%F0%F4%EE%EB%EE%E3%E8%FF), [2](https://habr.com/post/113626/), [3](http://wiki.technicalvision.ru/index.php/%D0%9C%D0%BE%D1%80%D1%84%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BE%D0%BF%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D0%B8_%D0%BD%D0%B0_%D0%B1%D0%B8%D0%BD%D0%B0%D1%80%D0%BD%D1%8B%D1%85_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%D1%85).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Эрозия\n",
    "Основная идея эрозии похожа только на эрозию почвы, она размывает границы объекта переднего плана (всегда старайтесь, чтобы передний план оставался белым). Так, что это делает? Ядро скользит по изображению (как в **2D**-свертке). Пиксель в исходном изображении ($1$ или $0$) будет считаться $1$, только если все пиксели под ядром равны $1$, в противном случае он размыт (обнуляется).\n",
    "\n",
    "Итак, что происходит, так это то, что все пиксели вблизи границы будут отбрасываться в зависимости от размера ядра. Таким образом, толщина или размер объекта переднего плана уменьшается или просто белая область уменьшается на изображении. Это полезно для удаления небольших белых шумов (как мы видели в главе о цветовом пространстве), отсоединения двух связанных объектов и т. д.\n",
    "\n",
    "Здесь, в качестве примера, я бы использовал полное ядро $5\\times5$. Давайте посмотрим, как это работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img/j.png')\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(erosion, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Растягивание\n",
    "Это просто противоположность эрозии. Здесь пиксельный элемент равен «$1$», если хотя бы один пиксель под ядром равен «$1$». Таким образом, увеличивается белая область в изображении или увеличивается размер объекта переднего плана. Обычно в таких случаях, как удаление шума, за эрозией следует расширение. Потому что эрозия удаляет белые шумы, но также уменьшает наш объект. Таким образом, мы расширяем это. Поскольку шум исчез, они не вернутся, но наша площадь объекта увеличивается. Это также полезно при соединении сломанных частей объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(dilation, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Открытие\n",
    "Открытие - это просто еще одно название эрозии, за которой следует расширение. Это полезно для удаления шума, как мы объяснили выше. Здесь мы используем функцию **cv2.morphologyEx()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.ones(noise_img.shape) * 255\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "opening = cv2.morphologyEx(noise_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(opening, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Закрытие\n",
    "Закрытие является обратным открытию, растягивание с последующей эрозией. Это полезно при закрытии небольших отверстий внутри объектов переднего плана или маленьких черных точек на объекте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.zeros(noise_img.shape)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "opening = cv2.morphologyEx(noise_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(opening, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Морфологический градиент\n",
    "Это разница между расширением и размыванием изображения.\n",
    "\n",
    "Результат будет выглядеть как контур объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(gradient, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа №3\n",
    "\n",
    "[Форма](https://forms.gle/oNLR6oQrSKGMHnhA6) для отправки решения.\n",
    "\n",
    "__ДЕДЛАЙНЫ__:\n",
    "\n",
    "Задача №1 - 21 июля 23:59\n",
    "\n",
    "Задача №2 - 23 июля 23:59\n",
    "\n",
    "Укажите в названии файла: \n",
    "1. имя и фамилия\n",
    "2. номер домашки\n",
    "3. номер задания\n",
    "\n",
    "(NAME_LES_TASK.ipynb)\n",
    "\n",
    "#### Задача №1 - Маска корабля\n",
    "\n",
    "В продолжении темы предыдущей задачи. Допустим, нам удалось понять, что на рассматриваемом изображении находится море. Значит, есть шанс на то, что можно найти корабли на картинке. \n",
    "\n",
    "Ваша задача - написать программу, которая отобразит маску* одного или нескольких кораблей на входном изображении. В приложении можно найти реальные спутниковые снимки кораблей. Подобные примеры изображений присутствуют в тесте.\n",
    "\n",
    "*Маска - геометрическое место точек какого-либо предмета на изображении. Обычно задается функцией $I(x,y)$.\n",
    "\n",
    "$I(x,y) = {\\begin{cases}0, &  (x,y) \\notin object \\\\ 1, & (x,y)\\in object \\end{cases}}$\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"https://i.ibb.co/HTxy4KY/test_image_01.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "    <td> <img src=\"https://i.ibb.co/9wDjMSg/test_image_06.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "    <td> <img src=\"https://i.ibb.co/yWCd3QQ/test_image_08.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача №2 - Хвост кита\n",
    "\n",
    "Не так давно на kaggle было соревнование по классификации горбатых китов по снимках их хвостов. Одним из приемов для улучшения работы нейронной сети было выделение маски хвоста. Затем по этой маске вырезался хвост на исходном изображенииа, нормировался, отображался на черный фон и подавался нейронной сети на вход. \n",
    "\n",
    "Ваша задача - написать программу, которая совершут предобработку картинки, писанную выше. Т.е. найти маску хвоста, по маске вырезать из исходного изображения хвост, нормировать хвост на заддный размер и поместить в центр пустой картинки. \n",
    "\n",
    "Изображения хвостов находятся в приложении к этому занятию.\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"https://i.ibb.co/fkScTsg/test_image_01.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "    <td> <img src=\"https://i.ibb.co/q7PQRtZ/test_image_03.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "    <td> <img src=\"https://i.ibb.co/StTqhST/test_image_08.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "</tr></table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
